input {
  file {  # default stat_interval 1 second # https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-discover_interval
    path => "/usr/share/logstash/tmpdata/crimes_sample*.csv"
    start_position => "beginning" 
    sincedb_path => "/dev/null" 
  }
}
filter{
  csv{
    separator => ","
    columns => ["ID","Case Number","Date","Block","IUCR","Primary Type","Description","Location Description","Arrest","Domestic",
    "Beat","District","Ward","Community Area","FBI Code","X Coordinate","Y Coordinate","Year","Updated On",
    "Latitude","Longitude","Location"]
  }
  mutate {
    convert => ["Latitude", "float"]
    convert => ["Longitude", "float"]
    convert => ["Year",  "integer"]
  }
  date{ 
    match => ["Date", "dd/MM/yyyy HH:mm:ss a"]
    target => ["Date"]  
    # target => "@timestamp"  
  }
  date{ 
    match => ["Updated On", "dd/MM/yyyy HH:mm:ss a"]
    target => ["Updated On"]
  }
}


output {
  elasticsearch {
    hosts => ["http://es01:9200"]
    index => "crimes-%{+YYYY.MM.dd}"
    template => "/usr/share/logstash/template/crimes_template.json"
    template_name=> "crime1"
    template_overwrite => "false"
  }
  stdout { codec => rubydebug }
}