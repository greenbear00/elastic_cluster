input {
  file {  # default stat_interval 1 second # https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-discover_interval
    path => "/usr/share/logstash/tmpdata/crimes_sample*.csv"
    start_position => "beginning" 
    sincedb_path => "/dev/null" 
  }
}
filter{
  csv{
    separator => ","
    columns => ["ID","Case Number","Date","Block","IUCR","Primary Type","Description","Location Description","Arrest","Domestic",
    "Beat","District","Ward","Community Area","FBI Code","X Coordinate","Y Coordinate","Year","Updated On",
    "Latitude","Longitude","Location"]
  }
  mutate {
    convert => ["Latitude", "float"]
    convert => ["Longitude", "float"]
    convert => ["Year",  "integer"]
    convert => ["ID", "integer"]
  }
  date{ 
    match => ["Date", "dd/MM/yyyy HH:mm:ss a"]
  target => ["@timestamp"] # 해당 필드를 kibana에서 보는 기준인 @timestamp 필드로 치환
  }
  date{ 
    match => ["Updated On", "dd/MM/yyyy HH:mm:ss a"]
    target => ["Updated On"]
  }
}


output {
  elasticsearch {
    hosts => ["http://es01:9200"]
    index => "crimes2-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}